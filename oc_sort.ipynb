{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1939e124-0e14-4fc3-a379-f4fac4d62fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/briancy2/.conda/envs/iwildcam/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0c0aa0-3c31-4897-95c0-5941098a408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261428/261428 [00:00<00:00, 1491130.13it/s]\n"
     ]
    }
   ],
   "source": [
    "META_DIR = \"data/metadata/metadata/\"\n",
    "TRAIN_DIR = \"data/train/train/\"\n",
    "TEST_DIR = \"data/test/test/\"\n",
    "\n",
    "test_data = json.load(open(META_DIR + 'iwildcam2022_test_information.json'))\n",
    "train_data = json.load(open(META_DIR + 'iwildcam2022_train_annotations.json'))\n",
    "\n",
    "#Test images\n",
    "df_test = pd.DataFrame({'id': [item['id'] for item in test_data['images']],\n",
    "                                'seq_id': [item['seq_id'] for item in test_data['images']],\n",
    "                                'file_name': [item['file_name'] for item in test_data['images']],\n",
    "                                'location': [item['location'] for item in test_data['images']],\n",
    "                                'seq_num_frames': [item['seq_num_frames'] for item in test_data['images']],\n",
    "                                'seq_frame_num': [item['seq_frame_num'] for item in test_data['images']]})\n",
    "#Train images\n",
    "df_train = pd.DataFrame({'id': [item['id'] for item in train_data['images']],\n",
    "                                'seq_id': [item['seq_id'] for item in train_data['images']],\n",
    "                                'file_name': [item['file_name'] for item in train_data['images']],\n",
    "                                'location': [item['location'] for item in train_data['images']],\n",
    "                                'seq_num_frames': [item['seq_num_frames'] for item in train_data['images']],\n",
    "                                'seq_frame_num': [item['seq_frame_num'] for item in train_data['images']]})\n",
    "# Detection for train test\n",
    "detections = json.load(open(META_DIR+\"iwildcam2022_mdv4_detections.json\"))['images']\n",
    "det_dict = dict()\n",
    "for detection in tqdm(detections):\n",
    "    det_dict[detection['file']] = detection['detections']\n",
    "df_detection = pd.DataFrame({'file': [item['file'] for item in detections],\n",
    "                                'detections': [item['detections'] for item in detections]})\n",
    "# Test sequence ids\n",
    "test_sequence_ids = pd.unique(df_test['seq_id'])\n",
    "# Train sequence id and count\n",
    "train_seq_count = pd.read_csv(META_DIR+\"train_sequence_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98fa6bb7-0ead-4d9e-83dd-0c7b9f682704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1780it [05:27,  5.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from deep_sort.deep_sort.ocsort import OCSort\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "file = open('submission_oc_det0.4.txt', 'w')\n",
    "file.write(\"Id,Predicted\")\n",
    "counts = []\n",
    "for index, seq_row in tqdm(train_seq_count.iterrows()) :\n",
    "    #print(\"######################### NEW SEQ ##################\")\n",
    "    #print(seq_row[\"seq_id\"])\n",
    "    img_rows = df_train.loc[df_train.seq_id == seq_row[\"seq_id\"]]\n",
    "    tracker = OCSort(det_thresh=0.4, max_age=30, min_hits=3, \n",
    "        iou_threshold=0, delta_t=3, asso_func=\"iou\", inertia=0.2, use_byte=False)\n",
    "    #results = []\n",
    "    outputs = []\n",
    "    for index, img_row in img_rows.iterrows():\n",
    "        image = Image.open(TRAIN_DIR+img_row['file_name'])\n",
    "        detections = df_detection.loc[df_detection.file == ('train/'+img_row['file_name'])]['detections'].to_list()[0]\n",
    "        dets = np.zeros((1, 4))\n",
    "        if detections:\n",
    "            dets = np.array([d[\"bbox\"] for d in detections])\n",
    "        cates = np.array([d[\"category\"] for d in detections])\n",
    "        confs = np.array([d[\"conf\"] for d in detections])\n",
    "        output = tracker.update_public(dets, cates, confs)\n",
    "        #print(\"detections\", detections)\n",
    "        #print(\"return\", output)\n",
    "        if not output.size == 0:\n",
    "            outputs.append(output[:,4].astype('float64').max())\n",
    "        \n",
    "    count = len(tracker.trackers)\n",
    "    if not len(outputs) == 0:\n",
    "        counts.append(max(outputs))\n",
    "    else:\n",
    "        counts.append(0)\n",
    "    #print(count, max(outputs))\n",
    "    file.write('\\n' + str(seq_row[\"seq_id\"]) + ',' + str(count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefd1ef-80fb-4fdf-8a83-f54ab3799e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1051it [03:19,  6.95it/s]"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from deep_sort.deep_sort.ocsort import OCSort\n",
    "from deep_sort.application_util.preprocessing import non_max_suppression\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "file = open('submission_oc_det0.5_suppress.txt', 'w')\n",
    "file.write(\"Id,Predicted\")\n",
    "counts = []\n",
    "for index, seq_row in tqdm(train_seq_count.iterrows()) :\n",
    "    #print(\"######################### NEW SEQ ##################\")\n",
    "    img_rows = df_train.loc[df_train.seq_id == seq_row[\"seq_id\"]]\n",
    "    tracker = OCSort(det_thresh=0.5, max_age=30, min_hits=3, \n",
    "        iou_threshold=0, delta_t=3, asso_func=\"iou\", inertia=0.2, use_byte=False)\n",
    "    #results = []\n",
    "    for index, img_row in img_rows.iterrows():\n",
    "        image = Image.open(TRAIN_DIR+img_row['file_name'])\n",
    "        detections = df_detection.loc[df_detection.file == ('train/'+img_row['file_name'])]['detections'].to_list()[0]\n",
    "        boxes = np.array([d[\"bbox\"] for d in detections])\n",
    "        scores = np.array([d[\"conf\"] for d in detections])\n",
    "        indices = non_max_suppression(boxes, 0.9, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "        dets = np.zeros((1, 4))\n",
    "        if detections:\n",
    "            dets = np.array([d[\"bbox\"] for d in detections])\n",
    "        cates = np.array([d[\"category\"] for d in detections])\n",
    "        confs = np.array([d[\"conf\"] for d in detections])\n",
    "        output = tracker.update_public(dets, cates, confs)\n",
    "        if not output.size == 0:\n",
    "            outputs.append(output[:,4].astype('float64').max())\n",
    "    #count = len(tracker.trackers)\n",
    "    if not len(outputs) == 0:\n",
    "        counts.append(max(outputs))\n",
    "    else:\n",
    "        counts.append(0)\n",
    "    file.write('\\n' + str(seq_row[\"seq_id\"]) + ',' + str(count))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f83307-3f59-4147-a27c-b96a4544911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/briancy2/iwildcam2022/deep_sort/deep_sort/ocsort.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  w = np.sqrt(x[2] * x[3])\n",
      "114it [00:40,  3.34it/s]/home/briancy2/iwildcam2022/deep_sort/deep_sort/ocsort.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  h = x[2] / w\n",
      "1162it [04:13,  9.20it/s]/home/briancy2/iwildcam2022/deep_sort/deep_sort/association.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "  o = wh / ((bboxes1[..., 2] - bboxes1[..., 0]) * (bboxes1[..., 3] - bboxes1[..., 1])\n",
      "1780it [06:20,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from deep_sort.deep_sort.ocsort import OCSort\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "file = open('submission_oc_det0.8.txt', 'w')\n",
    "file.write(\"Id,Predicted\")\n",
    "counts = []\n",
    "for index, seq_row in tqdm(train_seq_count.iterrows()) :\n",
    "    #print(\"######################### NEW SEQ ##################\")\n",
    "    img_rows = df_train.loc[df_train.seq_id == seq_row[\"seq_id\"]]\n",
    "    tracker = OCSort(det_thresh=0.8, max_age=30, min_hits=3, \n",
    "        iou_threshold=0, delta_t=3, asso_func=\"iou\", inertia=0.2, use_byte=False)\n",
    "    results = []\n",
    "    for index, img_row in img_rows.iterrows():\n",
    "        image = Image.open(TRAIN_DIR+img_row['file_name'])\n",
    "        detections = df_detection.loc[df_detection.file == ('train/'+img_row['file_name'])]['detections'].to_list()[0]\n",
    "        dets = np.zeros((1, 4))\n",
    "        if detections:\n",
    "            dets = np.array([d[\"bbox\"] for d in detections])\n",
    "        cates = np.array([d[\"category\"] for d in detections])\n",
    "        confs = np.array([d[\"conf\"] for d in detections])\n",
    "        output = tracker.update_public(dets, cates, confs)\n",
    "        #print(\"return\", output)\n",
    "    count = len(tracker.trackers)\n",
    "    counts.append(count)\n",
    "    file.write('\\n' + str(seq_row[\"seq_id\"]) + ',' + str(count))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17cc0619-31e9-4b45-bea9-c744d1eef181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1780it [04:34,  6.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "#file = open('submission_mdv40.95.txt', 'w')\n",
    "#file.write(\"Id,Predicted\")\n",
    "results = []\n",
    "for index, seq_row in tqdm(train_seq_count.iterrows()) :\n",
    "    base_counts = []\n",
    "    img_rows = df_train.loc[df_train.seq_id == seq_row[\"seq_id\"]]\n",
    "    for index, img_row in img_rows.iterrows():\n",
    "        #image = Image.open(TRAIN_DIR+img_row['file_name'])\n",
    "        detections = df_detection.loc[df_detection.file == ('train/'+img_row['file_name'])]['detections'].to_list()[0]\n",
    "        l = [d for d in detections if d[\"conf\"] > 0.95]\n",
    "        count=len(l)\n",
    "        base_counts.append(count)\n",
    "    results.append(max(base_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c820199-c14a-4871-9c27-168f74c47f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.mean(np.abs((np.array(counts) - train_seq_count[\"count\"].to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d8bce7c-06c2-4033-92cd-3066d3377aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.150561797752809\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1037782-f42a-4946-bc41-a28b0a0bf7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.   6.]\n",
      " [ -3. 176.]\n",
      " [ -2.  15.]\n",
      " [ -1.  31.]\n",
      " [  0.  71.]\n",
      " [  1. 156.]\n",
      " [  2. 259.]\n",
      " [  3. 351.]\n",
      " [  4. 307.]\n",
      " [  5. 408.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(np.unique((np.array(counts) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6b0d1bd-92f3-432e-9e3e-46d8583ed608",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1780,) (0,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_865358/2868447480.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_seq_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1780,) (0,) "
     ]
    }
   ],
   "source": [
    "loss = np.mean(np.abs(np.array(np.minimum(counts, np.array(results))) - train_seq_count[\"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53abfd10-9a4f-4e45-9752-861ea4981c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4662921348314606\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be8d5db-e2d5-4095-b35e-44b59877b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -8.   4.]\n",
      " [ -7.  15.]\n",
      " [ -6.  47.]\n",
      " [ -5.  44.]\n",
      " [ -4.  52.]\n",
      " [ -3.  66.]\n",
      " [ -2. 169.]\n",
      " [ -1. 399.]\n",
      " [  0. 903.]\n",
      " [  1.  74.]\n",
      " [  2.   7.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(np.unique((np.array(np.minimum(counts, np.array(results))) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f60b0a-b0fb-4547-816e-6736f91352d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1477fd48-6a59-430f-a03b-5fb57606a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780\n"
     ]
    }
   ],
   "source": [
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb81f7b1-b2d1-4f6e-be2d-2da30bf7b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4797752808988764\n",
      "[[ -8   1]\n",
      " [ -7   8]\n",
      " [ -6  22]\n",
      " [ -5  29]\n",
      " [ -4  39]\n",
      " [ -3  65]\n",
      " [ -2  99]\n",
      " [ -1 257]\n",
      " [  0 645]\n",
      " [  1 331]\n",
      " [  2 117]\n",
      " [  3  62]\n",
      " [  4  24]\n",
      " [  5  22]\n",
      " [  6  20]\n",
      " [  7   8]\n",
      " [  8   9]\n",
      " [  9   7]\n",
      " [ 10   1]\n",
      " [ 11   4]\n",
      " [ 12   3]\n",
      " [ 14   2]\n",
      " [ 18   4]\n",
      " [ 29   1]]\n"
     ]
    }
   ],
   "source": [
    "counts_oc = pd.read_csv('submission_oc_det0.5.txt')[\"Predicted\"].to_numpy()\n",
    "print(np.mean(np.abs((np.array(counts_oc) - train_seq_count[\"count\"].to_numpy()))))\n",
    "print(np.asarray(np.unique((np.array(counts_oc) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bd40e31-0d7e-4705-8481-9a9cda7cbdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4578651685393258\n",
      "[[ -8   3]\n",
      " [ -7  16]\n",
      " [ -6  28]\n",
      " [ -5  40]\n",
      " [ -4  55]\n",
      " [ -3  60]\n",
      " [ -2 117]\n",
      " [ -1 356]\n",
      " [  0 708]\n",
      " [  1 202]\n",
      " [  2  77]\n",
      " [  3  28]\n",
      " [  4  18]\n",
      " [  5  13]\n",
      " [  6  17]\n",
      " [  7  14]\n",
      " [  8   8]\n",
      " [  9   6]\n",
      " [ 10   3]\n",
      " [ 12   2]\n",
      " [ 14   3]\n",
      " [ 16   1]\n",
      " [ 17   1]\n",
      " [ 18   3]\n",
      " [ 23   1]]\n"
     ]
    }
   ],
   "source": [
    "counts_oc8 = pd.read_csv('submission_oc_det0.8.txt')[\"Predicted\"].to_numpy()\n",
    "merged_results = np.minimum(counts_oc8, np.array(results))\n",
    "print(np.mean(np.abs(counts_oc8 - train_seq_count[\"count\"].to_numpy())))\n",
    "print(np.asarray(np.unique((np.array(counts_oc8) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a264d-dfd4-4dd9-91b7-4c44b05d590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = np.minimum(counts_oc, np.array(results))\n",
    "print(np.mean(np.abs(merged_results - train_seq_count[\"count\"].to_numpy())))\n",
    "print(np.asarray(np.unique((np.array(merged_results) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6994ff66-faae-403f-be5a-a8eadd3aeb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780,) (1780,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(results).shape, counts_oc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04cd34d4-6dc5-4af6-af32-4de0e7b835d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3780898876404495\n",
      "[[ -9   3]\n",
      " [ -8  20]\n",
      " [ -7  18]\n",
      " [ -6  36]\n",
      " [ -5  41]\n",
      " [ -4  58]\n",
      " [ -3  96]\n",
      " [ -2 167]\n",
      " [ -1 432]\n",
      " [  0 604]\n",
      " [  1 216]\n",
      " [  2  63]\n",
      " [  3  18]\n",
      " [  4   5]\n",
      " [  5   1]\n",
      " [  6   2]]\n"
     ]
    }
   ],
   "source": [
    "counts_deep = pd.read_csv('submission_deep_conf_0.5_nn0.txt')[\"Predicted\"].to_numpy()\n",
    "print(np.mean(np.abs((np.array(counts_deep) - train_seq_count[\"count\"].to_numpy()))))\n",
    "print(np.asarray(np.unique((np.array(counts_deep) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd651f4-1311-44b5-8c19-d17443231c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1258426966292134\n",
      "[[ -8   3]\n",
      " [ -7  21]\n",
      " [ -6  48]\n",
      " [ -5  47]\n",
      " [ -4  55]\n",
      " [ -3  69]\n",
      " [ -2 184]\n",
      " [ -1 432]\n",
      " [  0 845]\n",
      " [  1  69]\n",
      " [  2   7]]\n"
     ]
    }
   ],
   "source": [
    "merged_deep = np.minimum(counts_deep, np.array(results))\n",
    "print(np.mean(np.abs(merged_results - train_seq_count[\"count\"].to_numpy())))\n",
    "print(np.asarray(np.unique((np.array(merged_results) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cfdd05a-eab3-4b17-ae3e-eb506988e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4797752808988764\n",
      "[[ -8   1]\n",
      " [ -7   8]\n",
      " [ -6  22]\n",
      " [ -5  29]\n",
      " [ -4  39]\n",
      " [ -3  65]\n",
      " [ -2  99]\n",
      " [ -1 257]\n",
      " [  0 645]\n",
      " [  1 331]\n",
      " [  2 117]\n",
      " [  3  62]\n",
      " [  4  24]\n",
      " [  5  22]\n",
      " [  6  20]\n",
      " [  7   8]\n",
      " [  8   9]\n",
      " [  9   7]\n",
      " [ 10   1]\n",
      " [ 11   4]\n",
      " [ 12   3]\n",
      " [ 14   2]\n",
      " [ 18   4]\n",
      " [ 29   1]]\n"
     ]
    }
   ],
   "source": [
    "counts_deep0 = pd.read_csv('submission_oc_det0.5.txt')[\"Predicted\"].to_numpy()\n",
    "print(np.mean(np.abs((np.array(counts_deep0) - train_seq_count[\"count\"].to_numpy()))))\n",
    "print(np.asarray(np.unique((np.array(counts_deep0) - train_seq_count[\"count\"]), return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ebaa1-b6ab-40a0-bbe0-b36c5a9248ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d42ac-d76f-4e98-a9b5-8cef71a4c6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6d956c-fb1e-42f7-82b4-44578543d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.mean(np.abs((np.array(counts) - train_seq_count[\"count\"].to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7de7770-3f61-4aec-b5b9-c0579aa97e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6578651685393258\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb436df-4842-4e5b-af00-859734940f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-iwildcam]",
   "language": "python",
   "name": "conda-env-.conda-iwildcam-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
