{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce347ef1-badf-495c-a13d-418c39010340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/briancy2/.conda/envs/iwildcam/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b0daca-a62f-495e-8de7-554fddf08f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261428/261428 [00:00<00:00, 1545939.36it/s]\n"
     ]
    }
   ],
   "source": [
    "META_DIR = \"data/metadata/metadata/\"\n",
    "TRAIN_DIR = \"data/train/train/\"\n",
    "TEST_DIR = \"data/test/test/\"\n",
    "\n",
    "test_data = json.load(open(META_DIR + 'iwildcam2022_test_information.json'))\n",
    "train_data = json.load(open(META_DIR + 'iwildcam2022_train_annotations.json'))\n",
    "\n",
    "#Test images\n",
    "df_test = pd.DataFrame({'id': [item['id'] for item in test_data['images']],\n",
    "                                'seq_id': [item['seq_id'] for item in test_data['images']],\n",
    "                                'file_name': [item['file_name'] for item in test_data['images']],\n",
    "                                'location': [item['location'] for item in test_data['images']],\n",
    "                                'seq_num_frames': [item['seq_num_frames'] for item in test_data['images']],\n",
    "                                'seq_frame_num': [item['seq_frame_num'] for item in test_data['images']]})\n",
    "#Train images\n",
    "df_train = pd.DataFrame({'id': [item['id'] for item in train_data['images']],\n",
    "                                'seq_id': [item['seq_id'] for item in train_data['images']],\n",
    "                                'file_name': [item['file_name'] for item in train_data['images']],\n",
    "                                'location': [item['location'] for item in train_data['images']],\n",
    "                                'seq_num_frames': [item['seq_num_frames'] for item in train_data['images']],\n",
    "                                'seq_frame_num': [item['seq_frame_num'] for item in train_data['images']]})\n",
    "# Detection for train test\n",
    "detections = json.load(open(META_DIR+\"iwildcam2022_mdv4_detections.json\"))['images']\n",
    "det_dict = dict()\n",
    "for detection in tqdm(detections):\n",
    "    det_dict[detection['file']] = detection['detections']\n",
    "df_detection = pd.DataFrame({'file': [item['file'] for item in detections],\n",
    "                                'detections': [item['detections'] for item in detections]})\n",
    "# Test sequence ids\n",
    "test_sequence_ids = pd.unique(df_test['seq_id'])\n",
    "# Train sequence id and count\n",
    "train_seq_count = pd.read_csv(META_DIR+\"train_sequence_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea5a056d-82f7-45c3-a4b0-13c4b5eb8ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1790939137.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3957484/1790939137.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    train_seq_count.\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_seq_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d6f1f-43a5-4b66-8ccc-0c5821b1b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5aa5bba-a681-4c3c-8459-5484f3f1c1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11028/11028 [19:35<00:00,  9.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from deep_sort.application_util import preprocessing\n",
    "from deep_sort.application_util import visualization\n",
    "from deep_sort.deep_sort import nn_matching\n",
    "from deep_sort.deep_sort.detection import Detection\n",
    "from deep_sort.deep_sort.tracker import Tracker\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "        \"cosine\", 0.2, 100)\n",
    "file = open('submission_deep8.txt', 'w')\n",
    "file.write(\"Id,Predicted\")\n",
    "for sequence_id in tqdm(test_sequence_ids):\n",
    "    tracker = Tracker(metric)\n",
    "    results = []\n",
    "    img_rows = df_test.loc[df_test.seq_id == sequence_id]\n",
    "    for index, img_row in img_rows.iterrows():\n",
    "        detections = df_detection.loc[df_detection.file == ('test/'+img_row['file_name'])]['detections'].to_list()[0]\n",
    "        img1 = im[:y, :]\n",
    "        img2 = im[y+h:imh, :]\n",
    "        \n",
    "        #print(set([d[\"category\"] for d in detections]))\n",
    "        detections = [Detection(tuple(det[\"bbox\"]), det[\"conf\"], []) for det in detections if det['conf']]\n",
    "        \n",
    "#         boxes = np.array([d for d in filtered_det])\n",
    "#         scores = np.array([d.confidence for d in detections])\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            results.append(track.track_id)\n",
    "    count = len(set(results))   \n",
    "    file.write('\\n' + str(sequence_id) + ',' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58065b21-0a61-4e3a-bd55-248db7d74d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 6086694] baseline deep sort is 0.428 - absolutely horrible\n",
      " 3 files changed, 325 insertions(+), 244 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -am \"baseline deep sort is 0.428 - absolutely horrible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7af39c1-0587-4bc3-b3d1-945924d7724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1780it [05:50,  5.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from deep_sort.application_util import preprocessing\n",
    "from deep_sort.application_util import visualization\n",
    "from deep_sort.deep_sort import nn_matching\n",
    "from deep_sort.deep_sort.detection import Detection\n",
    "from deep_sort.deep_sort.tracker import Tracker\n",
    "print(len(train_seq_count))\n",
    "file = open('submission_deep_test.txt', 'w')\n",
    "file.write(\"Id,Predicted\")\n",
    "counts = []\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "        \"cosine\", 0.2, 100)\n",
    "for index, seq_row in tqdm(train_seq_count.iterrows()) :\n",
    "    tracker = Tracker(metric)\n",
    "    results = []\n",
    "    img_rows = df_train.loc[df_train.seq_id == seq_row[\"seq_id\"]]\n",
    "    for index, img_row in img_rows.iterrows():\n",
    "        detections = df_detection.loc[df_detection.file == ('train/'+img_row['file_name'])]['detections'].to_list()[0]\n",
    "        detections = [Detection(tuple(det[\"bbox\"]), det[\"conf\"], []) for det in detections]\n",
    "#         boxes = np.array([d for d in filtered_det])\n",
    "#         scores = np.array([d.confidence for d in detections])\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            results.append(track.track_id)\n",
    "    count = len(set(results))   \n",
    "    counts.append(count)\n",
    "    file.write('\\n' + str(seq_row[\"seq_id\"]) + ',' + str(count))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-iwildcam]",
   "language": "python",
   "name": "conda-env-.conda-iwildcam-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
