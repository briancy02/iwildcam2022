{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce347ef1-badf-495c-a13d-418c39010340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/briancy2/.conda/envs/iwildcam/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b0daca-a62f-495e-8de7-554fddf08f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_DIR = \"data/metadata/metadata/\"\n",
    "TRAIN_DIR = \"data/train/train/\"\n",
    "\n",
    "test_data = json.load(open(META_DIR + 'iwildcam2022_test_information.json'))\n",
    "train_data = json.load(open(META_DIR + 'iwildcam2022_train_annotations.json'))\n",
    "\n",
    "#Test images\n",
    "df_test = pd.DataFrame({'id': [item['id'] for item in test_data['images']],\n",
    "                                'seq_id': [item['seq_id'] for item in test_data['images']],\n",
    "                                'file_name': [item['file_name'] for item in test_data['images']],\n",
    "                                'location': [item['location'] for item in test_data['images']],\n",
    "                                'seq_num_frames': [item['seq_num_frames'] for item in test_data['images']],\n",
    "                                'seq_frame_num': [item['seq_frame_num'] for item in test_data['images']]})\n",
    "#Train images\n",
    "df_train = pd.DataFrame({'id': [item['id'] for item in train_data['images']],\n",
    "                                'seq_id': [item['seq_id'] for item in train_data['images']],\n",
    "                                'file_name': [item['file_name'] for item in train_data['images']],\n",
    "                                'location': [item['location'] for item in train_data['images']],\n",
    "                                'seq_num_frames': [item['seq_num_frames'] for item in train_data['images']],\n",
    "                                'seq_frame_num': [item['seq_frame_num'] for item in train_data['images']]})\n",
    "# Detection for train test\n",
    "detections = json.load(open(META_DIR+\"iwildcam2022_mdv4_detections.json\"))['images']\n",
    "det_dict = dict()\n",
    "for detection in tqdm(detections):\n",
    "    det_dict[detection['file']] = detection['detections']\n",
    "df_detection = pd.DataFrame({'file': [item['file'] for item in detections],\n",
    "                                'detections': [item['detections'] for item in detections]})\n",
    "# Test sequence ids\n",
    "test_sequence_ids = pd.unique(df_test['seq_id'])\n",
    "# Train sequence id and count\n",
    "train_seq_count = pd.read_csv(META_DIR+\"train_sequence_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6caa6a7-0526-47ba-b384-ee3841b56489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c075470d-f818-49c7-957f-2dbaad069e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54b2514d-0e3c-4d3c-9b03-6f292178b70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    seq_id  count\n",
      "0     95dae922-21bc-11ea-a13a-137349068a90      9\n",
      "1     2fff6c8a-7d42-11eb-8fb5-0242ac1c0002      9\n",
      "2     300cc650-7d42-11eb-8fb5-0242ac1c0002      9\n",
      "3     30125958-7d42-11eb-8fb5-0242ac1c0002      9\n",
      "4     301d2d24-7d42-11eb-8fb5-0242ac1c0002      9\n",
      "...                                    ...    ...\n",
      "1775  9925c372-21bc-11ea-a13a-137349068a90      8\n",
      "1776  9932df3a-21bc-11ea-a13a-137349068a90      8\n",
      "1777  99556aa0-21bc-11ea-a13a-137349068a90      5\n",
      "1778  99577458-21bc-11ea-a13a-137349068a90      4\n",
      "1779  99592c3a-21bc-11ea-a13a-137349068a90      5\n",
      "\n",
      "[1780 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(seq_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b48b4d-1328-4a59-9be5-aa94a640f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in sequences:\n",
    "   cur_idx_row = self.seq_count.iloc[idx]\n",
    "#         y = int(cur_idx_row['count'])\n",
    "#         img_rows = self.df.loc[self.df.seq_id == cur_idx_row['seq_id']]\n",
    "#         out = torch.zeros(1024,1024,3,img_rows.iloc[0].seq_num_frames)\n",
    "#         for index, img_row in img_rows.iterrows():\n",
    "#            img_path = os.path.join(self.images_dir, img_row['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa5bba-a681-4c3c-8459-5484f3f1c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in sequences:\n",
    "        print(\"Running sequence %s\" % sequence)\n",
    "        sequence_dir = os.path.join(args.mot_dir, sequence)\n",
    "        detection_file = os.path.join(args.detection_dir, \"%s.npy\" % sequence)\n",
    "        output_file = os.path.join(args.output_dir, \"%s.txt\" % sequence)\n",
    "        deep_sort_app.run(\n",
    "            sequence_dir, detection_file, output_file, args.min_confidence,\n",
    "            args.nms_max_overlap, args.min_detection_height,\n",
    "            args.max_cosine_distance, args.nn_budget, display=False)\n",
    "        \n",
    "        \n",
    "    seq_info = gather_sequence_info(sequence_dir, detection_file)\n",
    "    metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "        \"cosine\", max_cosine_distance, nn_budget)\n",
    "    tracker = Tracker(metric)\n",
    "    results = []\n",
    "        detections = create_detections(\n",
    "            seq_info[\"detections\"], frame_idx, min_detection_height)\n",
    "        for row in detection_mat[mask]:\n",
    "        bbox, confidence, feature = row[2:6], row[6], row[10:]\n",
    "        detections = [d for d in detections if d.confidence >= min_confidence]\n",
    "\n",
    "        # Run non-maxima suppression.\n",
    "        boxes = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(\n",
    "            boxes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "\n",
    "        # Update tracker.\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Update visualization.\n",
    "        if display:\n",
    "            image = cv2.imread(\n",
    "                seq_info[\"image_filenames\"][frame_idx], cv2.IMREAD_COLOR)\n",
    "            vis.set_image(image.copy())\n",
    "            vis.draw_detections(detections)\n",
    "            vis.draw_trackers(tracker.tracks)\n",
    "\n",
    "        # Store results.\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlwh()\n",
    "            results.append([\n",
    "                frame_idx, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "    # Run tracker.\n",
    "    if display:\n",
    "        visualizer = visualization.Visualization(seq_info, update_ms=5)\n",
    "    else:\n",
    "        visualizer = visualization.NoVisualization(seq_info)\n",
    "    visualizer.run(frame_callback)\n",
    "\n",
    "    # Store results.\n",
    "    f = open(output_file, 'w')\n",
    "    for row in results:\n",
    "        print('%d,%d,%.2f,%.2f,%.2f,%.2f,1,-1,-1,-1' % (\n",
    "            row[0], row[1], row[2], row[3], row[4], row[5]),file=f)\n",
    "\n",
    "\n",
    "def bool_string(input_string):\n",
    "    if input_string not in {\"True\",\"False\"}:\n",
    "        raise ValueError(\"Please Enter a valid Ture/False choice\")\n",
    "    else:\n",
    "        return (input_string == \"True\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-iwildcam]",
   "language": "python",
   "name": "conda-env-.conda-iwildcam-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
